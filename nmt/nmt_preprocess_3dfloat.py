# -*- coding: utf-8 -*-
"""NMT_preprocess_3Dfloat.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IHR-yhUwBEBkD30zBwKy0m1GNKL878xF

1. 파일 로드 & 전처리
"""

cd drive/My Drive/NMT1

cd 형태소Json

import numpy as np
import pandas as pd
import json
import re

# json에서 형태소에 해당하는 부분만 남김
def preprocess_gloss(f):
  f = str(f)
  #print(f)
  f = re.sub(r'[^\w]','',f)
  f = re.sub(r'name',' ',f)
  f = re.sub(r'[a-zA-Z0-9_]','',f)
  f = re.sub(r'  ','',f)
  return f

# 테스트
with open("NIA_SL_SEN0060_REAL10_R_morpheme.json", "r", encoding="utf-8", errors='ignore') as f:
      f = json.load(f) 
      f = preprocess_gloss(f)

tmp_gloss = []
tmp_gloss.append(f)
tmp_gloss

# 형태소 json 데이터를 불러와서 str 형태로 data list에 넣기

gl = ["D"] #,"F","L","R","U"
gloss = []

for i in range(1,60): 
  i = str(i)
  for g in gl:
    with open("NIA_SL_SEN00" + i.zfill(2) + "_REAL06_"+ g + "_morpheme.json", "r", encoding="utf-8", errors='ignore') as f:
      f = json.load(f) 
      gloss.append(preprocess_gloss(f))

    with open("NIA_SL_SEN00" + i.zfill(2) + "_REAL10_"+ g + "_morpheme.json", "r", encoding="utf-8", errors='ignore') as f:
      f = json.load(f) 
      gloss.append(preprocess_gloss(f))

# data list 확인
gloss

gloss_=[]
for i in range(15):
  gloss_.append(gloss[i*4])

gloss_

# keypoint data도 동일하게 진행

cd ..

cd 키포인트Json

# 영상 데이터는 여러 개이다보니 list 혹은 array 형태로 들어갈 수 밖에 없는데 그러면 학습이 안됨
# 따라서 일단 { } [ ] 을 각각 $ % ^ & 으로 replace 하여 train, predict를 진행하고 
# 후에 predict한 데이터를 다시 replace 하는 방법을 사용하기로 함

import os

# json에서 형태소에 해당하는 부분만 남김 {} [] => $ % ^ & => {} []
def preprocess_keypoints(f):
  f = str(f)
  #print(k)
  f = re.sub(r'{','',f)
  f = re.sub(r'}','',f)
  f = re.sub(r'\[','',f)
  f = re.sub(r']','',f)

  f = re.sub(r'$\'version\': 1.3, \'people\': ^$\'person_id\': ^-1&, \'pose_keypoints_2d\': ^', '',f)
  f = re.sub(r'\'face_keypoints_2d\': ^', '5000.0, ', f)
  f = re.sub(r'\'hand_left_keypoints_2d\': ^','5000.0, ', f)
  f = re.sub(r'\'hand_right_keypoints_2d\': ^', '5000.0, ', f)
  f = re.sub(r'\'pose_keypoints_3d\': ^&, \'face_keypoints_3d\': ^&, \'hand_left_keypoints_3d\': ^&, \'hand_right_keypoints_3d\': ^&%&%\"', '',f)

  f = re.sub(r'\'version\': 1.3, \'people\': \'person_id\': -1, \'pose_keypoints_2d\': ', '',f)
  f = re.sub(r'\'face_keypoints_2d\': ', '5000.0, ', f)
  f = re.sub(r'\'hand_left_keypoints_2d\': ', '5000.0, ', f)
  f = re.sub(r'\'hand_right_keypoints_2d\': ', '5000.0, ', f)
  f = re.sub(r'\'pose_keypoints_3d\': , \'face_keypoints_3d\': , \'hand_left_keypoints_3d\': , \'hand_right_keypoints_3d\': ', '',f)
  
  return f

# 테스트

#tmp_sign = []

#for i in range (165):
#  i = str(i)
#  path2 = "NIA_SL_SEN0001_REAL06_D.mp4/NIA_SL_SEN0001_REAL06_D_000000000"+ i.zfill(3) +"_keypoints.json"
#  with open(path2, "r", encoding="utf-8", errors='ignore') as f:
#      f = json.load(f) 
#      f = preprocess_keypoints(f)
#      tmp_sign.append(f)

#tmp_sign

# '왼쪽' 의 수어 영상 키포인트 시퀀스 (이게 하나의 영상 데이터임)

"""### 이건 영상데이터 넣은 것! 실제로 해볼 땐 이 코드 사용 (근데 어휘- 수어 쌍 맞추는 건 제대로 확인 안하고 임의로 한 거라 수정해야됨)"""

sign_ = []

for j in range(15):
  j_=str(j+1)
  sign = []
  for i in range (120):
    i = str(i)
    path2 = "NIA_SL_SEN00"+j_.zfill(2)+"_REAL06_F.mp4/NIA_SL_SEN00"+j_.zfill(2)+"_REAL06_F_000000000"+ i.zfill(3) +"_keypoints.json"
    with open(path2, "r", encoding="utf-8", errors='ignore') as f:
        f = json.load(f) 
        f = preprocess_keypoints(f)
        sign.append(f)
  sign_.insert(j, sign)

sign_

X_data = pd.DataFrame(gloss_)
X_data

X = X_data[0].values
X

y_data = pd.DataFrame(sign_)
y_data

test= y_data[3][3]
test

# 정말 3중 list라는 방법 밖에 없을까...? 똑똑이 여러분 help....
y = []
for i in range(15):
  tmp=[]
  for j in range(120):
    y_l=y_data[j][i].split(",")[:-1]  
    tmp_tmp=[]
    for k in range(10):   
      y_ = float(y_l[k])
      tmp_tmp.append(y_)
    tmp.append(tmp_tmp)
  y.append(tmp)
y

y=np.array(y)
print(X.shape,y.shape)

"""2.토크나이징

 https://towardsdatascience.com/neural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac
"""

import pandas as pd
from sklearn.model_selection import train_test_split
import string
from string import digits
import re
from sklearn.utils import shuffle
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import LSTM, Input, Dense,Embedding, Concatenate, TimeDistributed
from tensorflow.keras.models import Model,load_model, model_from_json
from tensorflow.keras.utils import plot_model
from tensorflow.keras.preprocessing.text import one_hot, Tokenizer
from tensorflow.keras.callbacks import EarlyStopping
import pickle as pkl
import numpy as np

X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2)

X_test[2]

y_test[2]

def Max_length(data):
  max_length_ = max([len(x.split(' ')) for x in data])
  return max_length_

#412
#Training data
max_X= Max_length(X_train)
max_y= 120

#Test data
max_X_test = Max_length(X_test)
max_y_test=120

max_X, max_X_test, max_y, max_y_test

"""원래 NMT 원리대로 일단 해보려고

y를 string 취급, 토크나이징으로 sequence화 해서 돌려봤으나 성능이 안좋게 나옴 (키포인트는 맥락이 없으니 당연한 결과인 듯)

X의 경우 KoNLPy - Mecab으로 처리, y의 경우 토크나이징 없이, 숫자로 인식시켜서 진행하는 게 나을 듯 하여

string 형태는 tensor로 돌릴 수 없어서 y를 float 3D array로 바꾸어 진행 중

근데 차원이 안 맞아서 지금 맞추고 있음.
"""

#https://konlpy-ko.readthedocs.io/ko/v0.4.3/install/
# https://notebook.community/zzsza/TIL/pytorch/NLP-1
# 이 둘 참고하여 keras tokenizer을 konlpy로 수정하면 좋을듯 함

#! sudo apt-get install python-dev; pip install konlpy
#! sudo apt-get install curl
#! bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)

#from tensorflow.keras.preprocessing.text.Tokenizer
# 각 코드가 무슨 의미인지 궁금하다면 아래 링크 참고
# https://codetorial.net/tensorflow/natural_language_processing_in_tensorflow_01.html

Tok = Tokenizer()
Tok.fit_on_texts(X_train)
word2index = Tok.word_index
vocab_size_source = len(word2index) + 1

X_train = Tok.texts_to_sequences(X_train)
X_train = pad_sequences(X_train, maxlen=max_X, padding='post')
X_test = Tok.texts_to_sequences(X_test)
X_test = pad_sequences(X_test, maxlen=max_X, padding='post')

len(word2index)

#Tok_y = Tokenizer()
#Tok_y.fit_on_texts(y_train)
#word2index_y = Tok_y.word_index
vocab_size_target = 1200

#y_train = Tok_y.texts_to_sequences(y_train)
#y_train = pad_sequences(y_train, maxlen=max_y, padding='post',dtype='float32')
#y_test = Tok_y.texts_to_sequences(y_test)
#y_test = pad_sequences(y_test, maxlen=max_y, padding='post',dtype='float32')

vocab_size_source, vocab_size_target

X_train[3], y_train[3]

"""*1*) https://towardsdatascience.com/neural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac 참고하여  수정 용이하게 class로 만듦"""

import tensorflow as tf
import os
from tensorflow.python.keras.layers import Layer
from tensorflow.python.keras import backend as K

class Encoder(tf.keras.Model):

  def __init__(self, encoder_inputs,  latent_dim, vocab_size_source):
    super(Encoder, self).__init__()

    self.encoder_inputs = encoder_inputs  
    self.latent_dim=latent_dim 
    self.vocab_size_source=vocab_size_source

    self.enc_emb = tf.keras.layers.Embedding(vocab_size_source, latent_dim, trainable=True)
    self.encoder_lstm1 = tf.keras.layers.LSTM(latent_dim,return_sequences=True,return_state=True) 
    self.encoder_lstm2 = tf.keras.layers.LSTM(latent_dim,return_sequences=True,return_state=True) 
    self.encoder_lstm3 = tf.keras.layers.LSTM(latent_dim,return_state=True, return_sequences=True) 

  def call(self, i, j, k):
    x = self.enc_emb(self.encoder_inputs)
    encoder_output1, state_h1, state_c1 = self.encoder_lstm1(x)
    encoder_output2, state_h2, state_c2 = self.encoder_lstm2(encoder_output1)
    encoder_outputs, state_h, state_c = self.encoder_lstm3(encoder_output2)

    return encoder_outputs, state_h, state_c
    #return {'encoder_outputs': encoder_outputs, 'state_h': state_h, 'state_c': state_c}

class Decoder(tf.keras.Model):

  def __init__(self, decoder_inputs, latent_dim, vocab_size_target,state_h, state_c):
    super(Decoder, self).__init__()

    self.decoder_inputs = decoder_inputs
    self.latent_dim=latent_dim 
    self.vocab_size_target=vocab_size_target

    self.dec_emb = tf.keras.layers.Embedding(vocab_size_target, latent_dim, trainable=True)
    self.decoder_lstm = tf.keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True) 

  def call(self, i, j, k):
    x = self.dec_emb(self.decoder_inputs)
    decoder_outputs,decoder_fwd_state, decoder_back_state = self.decoder_lstm(x,initial_state=[state_h, state_c])

    return decoder_outputs,decoder_fwd_state, decoder_back_state

#https://github.com/thushv89/attention_keras/blob/master/src/layers/attention.py
class AttentionLayer(Layer):
    """
    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).
    There are three sets of weights introduced W_a, U_a, and V_a
     """

    def __init__(self, **kwargs):
        super(AttentionLayer, self).__init__(**kwargs)

    def build(self, input_shape):
        assert isinstance(input_shape, list)
        # Create a trainable weight variable for this layer.

        self.W_a = self.add_weight(name='W_a',
                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),
                                   initializer='uniform',
                                   trainable=True)
        self.U_a = self.add_weight(name='U_a',
                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),
                                   initializer='uniform',
                                   trainable=True)
        self.V_a = self.add_weight(name='V_a',
                                   shape=tf.TensorShape((input_shape[0][2], 1)),
                                   initializer='uniform',
                                   trainable=True)

        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end

    def call(self, inputs, verbose=False):
        """
        inputs: [encoder_output_sequence, decoder_output_sequence]
        """
        assert type(inputs) == list
        encoder_out_seq, decoder_out_seq = inputs
        if verbose:
            print('encoder_out_seq>', encoder_out_seq.shape)
            print('decoder_out_seq>', decoder_out_seq.shape)

        def energy_step(inputs, states):
            """ Step function for computing energy for a single decoder state
            inputs: (batchsize * 1 * de_in_dim)
            states: (batchsize * 1 * de_latent_dim)
            """

            assert_msg = "States must be an iterable. Got {} of type {}".format(states, type(states))
            assert isinstance(states, list) or isinstance(states, tuple), assert_msg

            """ Some parameters required for shaping tensors"""
            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]
            de_hidden = inputs.shape[-1]

            """ Computing S.Wa where S=[s0, s1, ..., si]"""
            # <= batch size * en_seq_len * latent_dim
            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)

            """ Computing hj.Ua """
            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim
            if verbose:
                print('Ua.h>', U_a_dot_h.shape)

            """ tanh(S.Wa + hj.Ua) """
            # <= batch_size*en_seq_len, latent_dim
            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)
            if verbose:
                print('Ws+Uh>', Ws_plus_Uh.shape)

            """ softmax(va.tanh(S.Wa + hj.Ua)) """
            # <= batch_size, en_seq_len
            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)
            # <= batch_size, en_seq_len
            e_i = K.softmax(e_i)

            if verbose:
                print('ei>', e_i.shape)

            return e_i, [e_i]

        def context_step(inputs, states):
            """ Step function for computing ci using ei """

            assert_msg = "States must be an iterable. Got {} of type {}".format(states, type(states))
            assert isinstance(states, list) or isinstance(states, tuple), assert_msg

            # <= batch_size, hidden_size
            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)
            if verbose:
                print('ci>', c_i.shape)
            return c_i, [c_i]

        fake_state_c = K.sum(encoder_out_seq, axis=1)
        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim

        """ Computing energy outputs """
        # e_outputs => (batch_size, de_seq_len, en_seq_len)
        last_out, e_outputs, _ = K.rnn(
            energy_step, decoder_out_seq, [fake_state_e],
        )

        """ Computing context vectors """
        last_out, c_outputs, _ = K.rnn(
            context_step, e_outputs, [fake_state_c],
        )

        return c_outputs, e_outputs

    def compute_output_shape(self, input_shape):
        """ Outputs produced by the layer """
        return [
            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),
            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))
        ]

latent_dim = 50

encoder_inputs=Input(shape=(max_X,))
encoder= Encoder(encoder_inputs, latent_dim, vocab_size_source)
encoder_outputs, state_h, state_c = encoder(0,0,0)

decoder_inputs=Input(shape=(None,)) 
decoder = Decoder(decoder_inputs, latent_dim, vocab_size_target,state_h, state_c)
decoder_outputs,decoder_fwd_state, decoder_back_state = decoder(0,0,0)

#Attention Layer
attn_layer = AttentionLayer(name='attention_layer') 
attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])

# Concat attention output and decoder LSTM output 
decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])

#Dense layer
decoder_dense = TimeDistributed(Dense(vocab_size_target, activation='softmax')) 
decoder_outputs = decoder_dense(decoder_concat_input)

model = Model([encoder_inputs, decoder_inputs], decoder_outputs)
plot_model(model, to_file='train_model.png', show_shapes=True)

model.compile(optimizer='Adam',
              loss='sparse_categorical_crossentropy', 
              metrics=['accuracy'])

es = EarlyStopping(monitor='val_loss', mode='min', verbose=1) # val_loss가 올라가면 멈춰주는 것

X_train.shape

X_test.shape

y_train.shape # (24,120,414)

y_test.shape # (6,120,414)

y_train = y_train.reshape(12,1200) #49680)
y_test = y_test.reshape(3,1200) #49680)

history = model.fit([X_train, y_train[:,:-1]], y_train.reshape(y_train.shape[0], y_train.shape[1],1)[:,1:], 
                    epochs=10, 
                    #callbacks=[es],
                    batch_size=1,
                    validation_data = ([X_test, y_test[:,:-1]],           y_test.reshape(y_test.shape[0], y_test.shape[1], 1)[:,1:]))

# 프레임 5개만 쓰면 멀쩡하게 잘 돌아가는데
# 프레임 전체를 (414개) 사용하면 OOM으로 터져버림 ㅎㅎㅎㅎㅎ...

from matplotlib import pyplot 
pyplot.plot(history.history['loss'], label='train') 
pyplot.plot(history.history['val_loss'], label='test') 
pyplot.legend() 
pyplot.show()

model_json = model.to_json()
with open("NMT_model.json", "w") as json_file:
    json_file.write(model_json)
    
# serialize weights to HDF5
model.save_weights("NMT_model_weight.h5")
print("Saved model to disk")

# loading the model architecture and asigning the weights
json_file = open('NMT_model.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
model_loaded = model_from_json(loaded_model_json, custom_objects={'AttentionLayer': AttentionLayer})
# load weights into new model
model_loaded.load_weights("NMT_model_weight.h5")

latent_dim=50

# encoder inference

encoder_inputs = model_loaded.input[0]  #loading encoder_inputs
encoder_outputs, state_h, state_c = model_loaded.layers[6].output #loading encoder_outputs
#print(encoder_outputs.shape)
encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])


# decoder inference

# Below tensors will hold the states of the previous time step
decoder_state_input_h = Input(shape=(latent_dim,))
decoder_state_input_c = Input(shape=(latent_dim,))
decoder_hidden_state_input = Input(shape=(2,latent_dim))

# Get the embeddings of the decoder sequence

decoder_inputs = model_loaded.layers[3].output
#print(decoder_inputs.shape)
dec_emb_layer = model_loaded.layers[5]
dec_emb2= dec_emb_layer(decoder_inputs)

# To predict the next word in the sequence, set the initial states to the states from the previous time step

decoder_lstm = model_loaded.layers[7]
decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])


#attention inference

attn_layer = model_loaded.layers[8]
attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])
concate = model_loaded.layers[9]
decoder_inf_concat = concate([decoder_outputs2, attn_out_inf])


# A dense softmax layer to generate prob dist. over the target vocabulary

decoder_dense = model_loaded.layers[10]
decoder_outputs2 = decoder_dense(decoder_inf_concat)


# Final decoder model

decoder_model = Model(
[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],
[decoder_outputs2] + [state_h2, state_c2])

def decode_sequence(input_seq):
    # Encode the input as state vectors.
    e_out, e_h, e_c = encoder_model.predict(input_seq)
    target_seq = np.zeros((1,1))
    output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])

    return output_tokens

index2word=Tok.index_word

def seq2text(input_seq):
    newString=''
    for i in input_seq:
      if(i!=0):
        newString=newString+index2word[i]+' '
    return newString

for i in range(3):  
  print("Input:",seq2text(X_test[i]))
  print("Original:",y_test[i])
  print("Predicted:",decode_sequence(X_test[i].reshape(1,2)))
  print("shape:", y_test[i].shape, " ",decode_sequence(X_test[i].reshape(1,2)).shape)
  print("\n")

"""original output은 원래대로 나옴 

predict output도 형태는 얼추 비슷하게 나옴 일치률은 많이 심각하게 노답이지만 

그런데 Input에는 대체 무슨 문제가 생긴 걸까...? 여전히 vector로 띄워보면 [0,0]이라고 뜬다

======================================================================================

일단 input은 tokenize & embedding 과정에서 뭔가 문제가 있는 듯 함, 수정해보자

output도 지금 기존 코드 그대로 따와서 Embedding이 포함되면서 0-1 사이 값으로 다 변해버린 것 같은데

임베딩 빼고 조사했던 논문들 참고해서 모델 구조 바꾸면 나아지지 않을까 싶음
"""

