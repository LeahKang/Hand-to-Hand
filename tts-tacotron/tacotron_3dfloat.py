# -*- coding: utf-8 -*-
"""Tacotron_3Dfloat.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rR-rdMP5HwuNSP1tGq-bhScoybpw0vr3

1. 파일 로드 & 전처리
"""

cd drive/My Drive/NMT1

cd 형태소Json

import numpy as np
import pandas as pd
import json
import re

# json에서 형태소에 해당하는 부분만 남김
def preprocess_gloss(f):
  f = str(f)
  #print(f)
  f = re.sub(r'[^\w]','',f)
  f = re.sub(r'name',' ',f)
  f = re.sub(r'[a-zA-Z0-9_]','',f)
  f = re.sub(r'  ','',f)
  return f

# 테스트
with open("NIA_SL_SEN0060_REAL10_R_morpheme.json", "r", encoding="utf-8", errors='ignore') as f:
      f = json.load(f) 
      f = preprocess_gloss(f)

tmp_gloss = []
tmp_gloss.append(f)
tmp_gloss

# 형태소 json 데이터를 불러와서 str 형태로 data list에 넣기

gl = ["D"] #,"F","L","R","U"
gloss = []

for i in range(1,60): 
  i = str(i)
  for g in gl:
    with open("NIA_SL_SEN00" + i.zfill(2) + "_REAL06_"+ g + "_morpheme.json", "r", encoding="utf-8", errors='ignore') as f:
      f = json.load(f) 
      gloss.append(preprocess_gloss(f))

    with open("NIA_SL_SEN00" + i.zfill(2) + "_REAL10_"+ g + "_morpheme.json", "r", encoding="utf-8", errors='ignore') as f:
      f = json.load(f) 
      gloss.append(preprocess_gloss(f))

# data list 확인
gloss

gloss_=[]
for i in range(30):
  gloss_.append(gloss[i*4])

gloss_

# keypoint data도 동일하게 진행

cd ..

cd 키포인트Json

# 영상 데이터는 여러 개이다보니 list 혹은 array 형태로 들어갈 수 밖에 없는데 그러면 학습이 안됨
# 따라서 일단 { } [ ] 을 각각 $ % ^ & 으로 replace 하여 train, predict를 진행하고 
# 후에 predict한 데이터를 다시 replace 하는 방법을 사용하기로 함

import os

# json에서 형태소에 해당하는 부분만 남김 {} [] => $ % ^ & => {} []
def preprocess_keypoints(f):
  f = str(f)
  #print(k)
  f = re.sub(r'{','',f)
  f = re.sub(r'}','',f)
  f = re.sub(r'\[','',f)
  f = re.sub(r']','',f)

  f = re.sub(r'$\'version\': 1.3, \'people\': ^$\'person_id\': ^-1&, \'pose_keypoints_2d\': ^', '',f)
  f = re.sub(r'\'face_keypoints_2d\': ^', '5000.0, ', f)
  f = re.sub(r'\'hand_left_keypoints_2d\': ^','5000.0, ', f)
  f = re.sub(r'\'hand_right_keypoints_2d\': ^', '5000.0, ', f)
  f = re.sub(r'\'pose_keypoints_3d\': ^&, \'face_keypoints_3d\': ^&, \'hand_left_keypoints_3d\': ^&, \'hand_right_keypoints_3d\': ^&%&%\"', '',f)

  f = re.sub(r'\'version\': 1.3, \'people\': \'person_id\': -1, \'pose_keypoints_2d\': ', '',f)
  f = re.sub(r'\'face_keypoints_2d\': ', '5000.0, ', f)
  f = re.sub(r'\'hand_left_keypoints_2d\': ', '5000.0, ', f)
  f = re.sub(r'\'hand_right_keypoints_2d\': ', '5000.0, ', f)
  f = re.sub(r'\'pose_keypoints_3d\': , \'face_keypoints_3d\': , \'hand_left_keypoints_3d\': , \'hand_right_keypoints_3d\': ', '',f)
  
  return f

# 테스트

#tmp_sign = []

#for i in range (165):
#  i = str(i)
#  path2 = "NIA_SL_SEN0001_REAL06_D.mp4/NIA_SL_SEN0001_REAL06_D_000000000"+ i.zfill(3) +"_keypoints.json"
#  with open(path2, "r", encoding="utf-8", errors='ignore') as f:
#      f = json.load(f) 
#      f = preprocess_keypoints(f)
#      tmp_sign.append(f)

#tmp_sign

# '왼쪽' 의 수어 영상 키포인트 시퀀스 (이게 하나의 영상 데이터임)

"""### 이건 영상데이터 넣은 것! 실제로 해볼 땐 이 코드 사용 (근데 어휘- 수어 쌍 맞추는 건 제대로 확인 안하고 임의로 한 거라 수정해야됨)"""

from tqdm import tqdm
import time

sign_ = []

for j in tqdm(range(30)):
  j_=str(j+1)
  sign = []
  for i in range (120):
    i = str(i)
    path2 = "NIA_SL_SEN00"+j_.zfill(2)+"_REAL06_F.mp4/NIA_SL_SEN00"+j_.zfill(2)+"_REAL06_F_000000000"+ i.zfill(3) +"_keypoints.json"
    with open(path2, "r", encoding="utf-8", errors='ignore') as f:
        f = json.load(f) 
        f = preprocess_keypoints(f)
        sign.append(f)
  sign_.insert(j, sign)

sign_

X_data = pd.DataFrame(gloss_)
X_data

X = X_data[0].values
X

y_data = pd.DataFrame(sign_)
y_data

y = []
for i in tqdm(range(30)):
  tmp=[]
  for j in range(120):
    y_l=y_data[j][i].split(",")[:-1]  
    tmp_tmp=[]
    for k in range(414):   
      y_ = float(y_l[k])
      tmp_tmp.append(y_)
    tmp.append(tmp_tmp)
  y.append(tmp)
y

y=np.array(y)
print(X.shape,y.shape)

"""2.토크나이징

 https://towardsdatascience.com/neural-machine-translation-nmt-with-attention-mechanism-5e59b57bd2ac
"""

import pandas as pd
from sklearn.model_selection import train_test_split
import string
from string import digits
import re
from sklearn.utils import shuffle
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import LSTM, Input, Dense,Embedding, Concatenate, TimeDistributed
from tensorflow.keras.models import Model,load_model, model_from_json
from tensorflow.keras.utils import plot_model
from tensorflow.keras.preprocessing.text import one_hot, Tokenizer
from tensorflow.keras.callbacks import EarlyStopping
import pickle as pkl
import numpy as np

X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.3)

X_test[1]

y_test[1]

def Max_length(data):
  max_length_ = max([len(x.split(' ')) for x in data])
  return max_length_

#412
#Training data
max_X= Max_length(X_train)
max_y= 120 #49680

#Test data
max_X_test = Max_length(X_test)
max_y_test=120 #49680

max_X, max_X_test, max_y, max_y_test

#https://konlpy-ko.readthedocs.io/ko/v0.4.3/install/
# https://notebook.community/zzsza/TIL/pytorch/NLP-1
# 이 둘 참고하여 keras tokenizer을 konlpy로 수정하면 좋을듯 함

#! sudo apt-get install python-dev; pip install konlpy
#! sudo apt-get install curl
#! bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)

#from tensorflow.keras.preprocessing.text.Tokenizer
# 각 코드가 무슨 의미인지 궁금하다면 아래 링크 참고
# https://codetorial.net/tensorflow/natural_language_processing_in_tensorflow_01.html

Tok = Tokenizer()
Tok.fit_on_texts(X_train)
word2index = Tok.word_index
vocab_size_source = len(word2index) + 1

X_train = Tok.texts_to_sequences(X_train)
X_train = pad_sequences(X_train, maxlen=max_X, padding='post')
X_test = Tok.texts_to_sequences(X_test)
X_test = pad_sequences(X_test, maxlen=max_X, padding='post')

#Tok_y = Tokenizer()
#Tok_y.fit_on_texts(y_train)
#word2index_y = Tok_y.word_index
vocab_size_target = 120 #49680  #414*120=49680

#y_train = Tok_y.texts_to_sequences(y_train)
#y_train = pad_sequences(y_train, maxlen=max_y, padding='post',dtype='float32')
#y_test = Tok_y.texts_to_sequences(y_test)
#y_test = pad_sequences(y_test, maxlen=max_y, padding='post',dtype='float32')

vocab_size_source, vocab_size_target

X_train[3], y_train[3]

"""1) 트레인

이 코드 참고

https://github.com/Stevel705/Tacotron-2-keras
"""

import tensorflow as tf
import os
from tensorflow.python.keras.layers import Layer
from tensorflow.python.keras import backend as K

import keras.initializers as k_init
from keras.layers import (Conv1D, Dense, Activation, MaxPooling1D, Add,
                          Concatenate, Bidirectional, GRU, Dropout,
                          BatchNormalization, Lambda, Dot, Multiply)
from keras.layers import Input, Embedding, concatenate, RepeatVector, Dense, Reshape

N_MEL = 414 #80
REF_DB = 2 #20
MAX_DB = 10 #100
r = 5 # 몇개 연속으로 return 할지
MAX_MEL_TIME_LENGTH = 120 # 200 # Maximum size of the time dimension for a mel spectrogram
WINDOW_TYPE='hann' #?
N_ITER = 5 #50

# Text
NB_CHARS_MAX = 16  # max_X, 200, Size of the input text data

# Deep Learning Model
K1 = 16  # Size of the convolution bank in the encoder CBHG
K2 = 8  # Size of the convolution bank in the post processing CBHG
BATCH_SIZE = 1 #32
NB_EPOCHS = 15 #50
EMBEDDING_SIZE = 8 #256

# Other
TRAIN_SET_RATIO = 0.7 # 0.9

class Encoder(tf.keras.Model):

  def __init__(self, max_X, latent_dim, vocab_size_source, k1):
    super(Encoder, self).__init__()

    self.k1=k1
    self.max_X = max_X
    self.latent_dim=latent_dim  
    self.vocab_size_source=vocab_size_source

    self.enc_emb = tf.keras.layers.Embedding(vocab_size_source, latent_dim, trainable=True)

  def get_pre_net(self, input_data):
    
    prenet = Dense(256)(input_data)
    prenet = Activation('relu')(prenet)
    prenet = Dropout(0.5)(prenet)
    prenet = Dense(128)(prenet)
    prenet = Activation('relu')(prenet)
    prenet = Dropout(0.5)(prenet)

    return prenet

  def get_conv1dbank(self, K_, input_data):
    conv = Conv1D(filters=128, kernel_size=1,
                  strides=1, padding='same')(input_data)
    conv = BatchNormalization()(conv)
    conv = Activation('relu')(conv)

    for k_ in range(2, K_ + 1):
        conv = Conv1D(filters=128, kernel_size=k_,
                      strides=1, padding='same')(conv)
        conv = BatchNormalization()(conv)
        conv = Activation('relu')(conv)

    return conv

  def get_highway_output(self, highway_input, nb_layers, activation="tanh", bias=-3):
    
    dim = K.int_shape(highway_input)[-1]  # dimension must be the same
    initial_bias = k_init.Constant(bias)
    for n in range(nb_layers):
        H = Dense(units=dim, bias_initializer=initial_bias)(highway_input)
        H = Activation("sigmoid")(H)
        carry_gate = Lambda(lambda x: 1.0 - x,
                            output_shape=(dim,))(H)
        transform_gate = Dense(units=dim)(highway_input)
        transform_gate = Activation(activation)(transform_gate)
        transformed = Multiply()([H, transform_gate])
        carried = Multiply()([carry_gate, highway_input])
        highway_output = Add()([transformed, carried])
    return highway_output

  def get_CBHG_encoder(self, input_data, K_CBHG):
    
    conv1dbank = self.get_conv1dbank(K_CBHG, input_data)
    conv1dbank = MaxPooling1D(pool_size=2, strides=1,
                              padding='same')(conv1dbank)
    conv1dbank = Conv1D(filters=128, kernel_size=3,
                        strides=1, padding='same')(conv1dbank)
    conv1dbank = BatchNormalization()(conv1dbank)
    conv1dbank = Activation('relu')(conv1dbank)
    conv1dbank = Conv1D(filters=128, kernel_size=3,
                        strides=1, padding='same')(conv1dbank)
    conv1dbank = BatchNormalization()(conv1dbank)

    residual = Add()([input_data, conv1dbank])

    highway_net = self.get_highway_output(residual, 4, activation='relu')

    CBHG_encoder = Bidirectional(GRU(128, return_sequences=True))(highway_net)

    return CBHG_encoder

  def call(self, i, j):
    input_encoder = Input(shape=(self.max_X,))
    input_encoder_ = self.enc_emb(input_encoder)
    prenet_encoding = self.get_pre_net(input_encoder_)
    cbhg_encoding = self.get_CBHG_encoder(prenet_encoding, self.k1)
    # k1 = 16, Size of the convolution bank in the encoder CBHG

    return input_encoder, cbhg_encoding

class Decoder_prenet(tf.keras.Model):

  def __init__(self, n_mels, latent_dim, vocab_size_target):
    super(Decoder_prenet, self).__init__()

    self.n_mels=n_mels 
    self.latent_dim=latent_dim 
    self.vocab_size_target=vocab_size_target

    self.dec_emb = tf.keras.layers.Embedding(vocab_size_target, latent_dim, trainable=True)

  def get_pre_net(self, input_data):
    
    prenet = Dense(256)(input_data)
    prenet = Activation('relu')(prenet)
    prenet = Dropout(0.5)(prenet)
    prenet = Dense(128)(prenet)
    prenet = Activation('relu')(prenet)
    prenet = Dropout(0.5)(prenet)

    return prenet

  def get_attention_RNN(self):
    return GRU(256)

  def call(self, i, j):
    input_decoder = Input(shape=(None, self.n_mels)) 
    input_decoder_ = self.dec_emb(input_decoder)
    # n_mels = 80, 기존엔 0이었는데 what's mean?, 2D array라서?

    prenet_decoding = self.get_pre_net(input_decoder)
    attention_rnn_output = self.get_attention_RNN()(prenet_decoding)

    return input_decoder, attention_rnn_output

class Attention(tf.keras.Model):

  def __init__(self, max_X, cbhg_encoding, attention_rnn_output ):
      super(Attention, self).__init__()
      self.max_X = max_X
      self.cbhg_encoding = cbhg_encoding
      self.attention_rnn_output = attention_rnn_output

  def get_attention_context(self,encoder_output, attention_rnn_output):
      attention_input = Concatenate(axis=-1)([encoder_output,
                                              attention_rnn_output])
      e = Dense(10, activation="tanh")(attention_input)
      energies = Dense(1, activation="relu")(e)
      attention_weights = Activation('softmax')(energies)
      context = Dot(axes=1)([attention_weights,
                            encoder_output])

      return context

  def call(self, i, j):
      attention_rnn_output_repeated = RepeatVector(self.max_X)(self.attention_rnn_output)
      #attention_rnn_output from decoder

      attention_context = self.get_attention_context(self.cbhg_encoding, attention_rnn_output_repeated)
      #cbhg_encoding from encoder

      context_shape1 = int(attention_context.shape[1])
      context_shape2 = int(attention_context.shape[2])
      attention_rnn_output_reshaped = Reshape((context_shape1, context_shape2))(self.attention_rnn_output)

      return attention_context, attention_rnn_output_reshaped

class Decoder(tf.keras.Model):

  def __init__(self, attention_context, attention_rnn_output_reshaped, mel_time_length, n_mels):
    super(Decoder, self).__init__()
    
    self.r = r
    self.n_mels = n_mels
    self.mel_time_length = mel_time_length
    self.attention_context = attention_context
    self.attention_rnn_output_reshaped = attention_rnn_output_reshaped


  def get_decoder_RNN_output(self, input_data):

    rnn1 = GRU(256, return_sequences=True)(input_data)

    inp2 = Add()([input_data, rnn1])
    rnn2 = GRU(256)(inp2)

    decoder_rnn = Add()([inp2, rnn2])

    return decoder_rnn

  def get_conv1dbank(self, K_, input_data):
    conv = Conv1D(filters=128, kernel_size=1,
                  strides=1, padding='same')(input_data)
    conv = BatchNormalization()(conv)
    conv = Activation('relu')(conv)

    for k_ in range(2, K_ + 1):
        conv = Conv1D(filters=128, kernel_size=k_,
                      strides=1, padding='same')(conv)
        conv = BatchNormalization()(conv)
        conv = Activation('relu')(conv)

    return conv
    
  def get_highway_output(self, highway_input, nb_layers, activation="tanh", bias=-3):
    
    dim = K.int_shape(highway_input)[-1]  # dimension must be the same
    initial_bias = k_init.Constant(bias)
    for n in range(nb_layers):
        H = Dense(units=dim, bias_initializer=initial_bias)(highway_input)
        H = Activation("sigmoid")(H)
        carry_gate = Lambda(lambda x: 1.0 - x,
                            output_shape=(dim,))(H)
        transform_gate = Dense(units=dim)(highway_input)
        transform_gate = Activation(activation)(transform_gate)
        transformed = Multiply()([H, transform_gate])
        carried = Multiply()([carry_gate, highway_input])
        highway_output = Add()([transformed, carried])

    return highway_output

  def get_CBHG_post_process(self, input_data, K_CBHG):

    conv1dbank = self.get_conv1dbank(K_CBHG, input_data)
    conv1dbank = MaxPooling1D(pool_size=2, strides=1,
                              padding='same')(conv1dbank)
    conv1dbank = Conv1D(filters=256, kernel_size=3,
                        strides=1, padding='same')(conv1dbank)
    conv1dbank = BatchNormalization()(conv1dbank)
    conv1dbank = Activation('relu')(conv1dbank)
    conv1dbank = Conv1D(filters=80, kernel_size=3,
                        strides=1, padding='same')(conv1dbank)
    conv1dbank = BatchNormalization()(conv1dbank)

    residual = Add()([input_data, conv1dbank])

    highway_net = self.get_highway_output(residual, 4, activation='relu')

    CBHG_encoder = Bidirectional(GRU(128))(highway_net)

    return CBHG_encoder

  def call(self, i):

    input_of_decoder_rnn = concatenate([self.attention_context, self.attention_rnn_output_reshaped])
    input_of_decoder_rnn_projected = Dense(256)(input_of_decoder_rnn)
    output_of_decoder_rnn = self.get_decoder_RNN_output(input_of_decoder_rnn_projected)
    
    # mel_hat=TimeDistributed(Dense(n_mels*r))(output_of_decoder_rnn)
    mel_hat = Dense(self.mel_time_length * self.n_mels)(output_of_decoder_rnn)
    mel_hat_ = Reshape((self.mel_time_length, self.n_mels))(mel_hat)

    # mel_time_length... 아마 여기에 120, n_mel에 414가 들어가면 되지 않을까 싶음
    # 이 코드에서는 200, 80임. array shape가 맞을 듯

    #def slice(x):
    #    return x[:, :, -n_mels:]

    #mel_hat_last_frame = Lambda(slice)(mel_hat_)
    #post_process_output = self.get_CBHG_post_process(mel_hat_last_frame,
    #                                            k2)
    #z_hat = Dense(mag_time_length * (1 + n_fft // 2))(post_process_output)
    #z_hat_ = Reshape((mag_time_length, (1 + n_fft // 2)))(z_hat)
    # spectrogram의 time dim인데 이 부분은 코드 자체를 지우자

    return mel_hat_ #,z_hat_

latent_dim = 50

encoder = Encoder(max_X, latent_dim, vocab_size_source, K1) 
input_encoder, cbhg_encoding = encoder(0,0)

decoder_prenet = Decoder_prenet(N_MEL, latent_dim, vocab_size_target)
input_decoder, attention_rnn_output = decoder_prenet(0,0)

attention = Attention(max_X, cbhg_encoding, attention_rnn_output)
attention_context, attention_rnn_output_reshaped =attention(0,0)

decoder = Decoder(attention_context, attention_rnn_output_reshaped, MAX_MEL_TIME_LENGTH, N_MEL)
mel_hat_ =decoder(0) #z_hat

model = Model([input_encoder, input_decoder], outputs=mel_hat_)
plot_model(model, to_file='train_model.png', show_shapes=True)

from keras.optimizers import Adam
opt = Adam()
model.compile(optimizer=opt,
              loss=['mean_absolute_error', 'mean_absolute_error'])

es = EarlyStopping(monitor='val_loss', mode='min', verbose=1) # val_loss가 올라가면 멈춰주는 것

decoder_input = []
mel_spectro_data = []

decod_inp = tf.concat((tf.zeros_like(y[:1, :]),
                              y[:-1, :]), 0)
decod_inp = decod_inp[:, -N_MEL:]

# Padding of the temporal dimension
dim0_mel_spectro = y.shape[0]
dim1_mel_spectro = y.shape[1]
dim2_mel_spectro = y.shape[2]
padded_mel_spectro = np.zeros((dim0_mel_spectro, dim1_mel_spectro, dim2_mel_spectro))
padded_mel_spectro[:dim0_mel_spectro, :dim1_mel_spectro] = y


dim0_decod_inp = decod_inp.shape[0]
dim1_decod_inp = decod_inp.shape[1]
dim2_decod_inp = decod_inp.shape[2]
padded_decod_input = np.zeros((dim0_decod_inp, dim1_decod_inp, dim2_decod_inp))
padded_decod_input[:dim0_decod_inp, :dim1_decod_inp] = decod_inp

#mel_spectro_data.append(padded_mel_spectro)
#decoder_input.append(padded_decod_input)

decoder_input_array = np.array(padded_decod_input)
mel_spectro_data_array = np.array(padded_mel_spectro)


len_train = int(TRAIN_SET_RATIO * len(y))
print(len_train)
print(decoder_input_array.shape)

decoder_input_array_training = decoder_input_array[:len_train]
decoder_input_array_testing = decoder_input_array[len_train:]

mel_spectro_data_array_training = mel_spectro_data_array[:len_train]
mel_spectro_data_array_testing = mel_spectro_data_array[len_train:]

print(MAX_MEL_TIME_LENGTH)

X_train.shape

mel_spectro_data_array_testing.shape

train_history = model.fit([X_train, decoder_input_array_training],
                          mel_spectro_data_array_training,
                          epochs=150, batch_size=BATCH_SIZE,
                          verbose=1, validation_split=0.2)

from matplotlib import pyplot 
pyplot.plot(train_history.history['loss'], label='train') 
pyplot.plot(train_history.history['val_loss'], label='test') 
pyplot.legend() 
pyplot.show()

#saved_model = load_model('results/model.h5')
predictions = model.predict([X_test, decoder_input_array_testing])

index2word=Tok.index_word
def seq2text(input_seq):
    newString=''
    for i in input_seq:
      if(i!=0):
        newString=newString+index2word[i]+' '
    return newString

for i in range(len(X_test)):

    print("num of test data is", i)
    print(seq2text(X_test[i]))
    print(X_test[i])
    print("test: ", y_test[i])
    print("predict: ",predictions[i])
    print("===================================")

# 1, 3, 4, 7 빼고는 다 사라졌다...ㅎㅎㅎ 
# 불용어 처리 되어서 그런 것 같은데 이거 전처리단에서 해결해야할 듯

cd ..

cd result

ls = [1,3,4,7]
for i in ls:
  predict = predictions[l].tolist()
  i=str(i)
  with open('result'+i+'.json', 'w', encoding='utf-8') as make_file:
    json.dump(predict, make_file, indent="\t")